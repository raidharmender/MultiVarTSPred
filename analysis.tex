\textbf{Time series and its importance}

1. Time-Series(TS) is a sequence of measurements on the same variable collected over time.
1. It is a set of observations, each one being recorded at equally spaced time interval.
1. We extrapolate a past trend to predict future such as movement of short-term interest rate, capacity demand in airline and other sectors.

\textbf{Multivariate-time series analysis and prediction using incomplete data}

1. TS data is collected for multiple variables over the same period of time. For example, a country's unemployment, GDP and inflation data over an interval period.
1. The TS data measures the changes over time. The time column in the data structure is used to sort the data.
1. TS analsis has played major role in areas like fraud detection, spam email filtering, finance, weather, healthcare, space exploration, manufactoring et al.

\textbf{How to predict future using TS?}

1. Simple deterministic model such as linear extrapolation
2. Complex deep learning approaches

\textbf{TS data intervals}

The interval depends on the nature of forecasting. For example, for a nation's GDP, we use yearly interval while sales data can be monthly and air-quality index being monitored on hourly basis.

\textbf{Challenges with time-series analysis}

1. Data is not independent.
1. Data order is important to keep the data structure intact
1. Order is also important as data is list of observations

\textbf{Handling missing values}

\textbf{Why DL approach has performed not so well for univariate time series forecasting compared to naive and classical forecasting methods?}

Deep learning (DL) approaches have shown remarkable success in various fields, including computer vision, natural language processing, and speech recognition. However, when it comes to univariate time series forecasting, DL models have not always outperformed classical and naive forecasting methods.

There are several reasons why DL approaches may not perform as well for univariate time series forecasting:

Lack of data: DL models require a large amount of data to train effectively. In some cases, univariate time series data may not be abundant, making it challenging for DL models to learn patterns and make accurate predictions.

Overfitting: DL models are prone to overfitting when the training data is not representative of the test data. This is especially problematic when working with time series data, as there may be hidden patterns and trends that are not captured in the training data.

Complexity: DL models can be very complex and have many parameters to tune. This can make it challenging to find the optimal architecture and hyperparameters for a particular time series problem.

Interpretability: DL models can be challenging to interpret, making it difficult to understand why they are making certain predictions. This can be a significant drawback in some applications, where interpretability is crucial.

Performance metric: DL models are often evaluated using mean squared error (MSE) or mean absolute error (MAE). While these metrics are useful for measuring the accuracy of point forecasts, they may not be the best metrics for evaluating the overall performance of a time series forecasting model.

In contrast, classical and naive forecasting methods, such as ARIMA and exponential smoothing, have been developed specifically for time series forecasting and have been shown to perform well in many cases. These methods are often simpler to implement and interpret than DL models and can be effective when working with smaller datasets. Additionally, classical and naive methods often have well-established performance metrics, such as AIC or BIC, that can be used to evaluate the overall performance of a model.

Overall, DL approaches can be a powerful tool for time series forecasting, but they may not always outperform classical and naive methods, especially when working with small datasets or when interpretability
